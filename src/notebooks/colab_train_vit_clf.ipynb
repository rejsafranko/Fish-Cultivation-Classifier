{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rejsa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    ViTFeatureExtractor,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_vit_clf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "def create_dataloaders_and_mappings(data_path):\n",
    "    dataset = load_dataset(\"imagefolder\", data_dir=data_path)\n",
    "\n",
    "    splits = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "    dataset[\"train\"] = splits[\"train\"]\n",
    "    dataset[\"val\"] = splits[\"test\"]\n",
    "\n",
    "    id2label = {\n",
    "        id: label for id, label in enumerate(dataset[\"train\"].features[\"label\"].names)\n",
    "    }\n",
    "\n",
    "    label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "    return dataset, id2label, label2id\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric1 = load_metric(\"accuracy\")\n",
    "    metric2 = load_metric(\"precision\")\n",
    "    metric3 = load_metric(\"recall\")\n",
    "    metric4 = load_metric(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision = metric2.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )[\"precision\"]\n",
    "    recall = metric3.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )[\"recall\"]\n",
    "    f1 = metric4.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "def main():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    colab_data_path = \"/content/drive/MyDrive/Seminar2/data/ribe_512x768\"\n",
    "    colab_dir = \"/content/drive/MyDrive/Seminar2/model\"\n",
    "    model_id = \"google/vit-base-patch16-224\"\n",
    "\n",
    "    dataset, id2label, label2id = create_dataloaders_and_mappings(colab_data_path)\n",
    "\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "    def transform(example_batch):\n",
    "        inputs = feature_extractor(\n",
    "            [x.convert(\"RGB\") for x in example_batch[\"image\"]], return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs[\"labels\"] = example_batch[\"label\"]\n",
    "        return inputs\n",
    "\n",
    "    dataset = dataset.with_transform(transform)\n",
    "\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_id,\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=colab_dir,\n",
    "        per_device_train_batch_size=16,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=4,\n",
    "        fp16=True,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"tensorboard\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"val\"],\n",
    "        tokenizer=feature_extractor,\n",
    "    )\n",
    "\n",
    "    train_results = trainer.train()\n",
    "    trainer.save_model()\n",
    "    trainer.log_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    metrics = trainer.evaluate(dataset[\"test\"])\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
